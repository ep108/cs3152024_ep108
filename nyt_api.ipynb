{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice with NYTimes API\n",
    "CS315: Data Science for the Web  \n",
    "Professor Eni Mustafaraj  \n",
    "[Day 10 Slides 22-28](https://docs.google.com/presentation/d/15fuBhqPNv8GgeqNlNydKAlJW5ecAx92h7lQ_KyTxbKI/edit#slide=id.g2bd1c28673c_0_127)  \n",
    "Edith Po  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '1DFmIMxxqdYl8wJBPqAFxtHkimk86Qtn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.nytimes.com/svc/archive/v1/2024/2.json?api-key=1DFmIMxxqdYl8wJBPqAFxtHkimk86Qtn\n"
     ]
    }
   ],
   "source": [
    "year = 2024\n",
    "month = 2\n",
    "\n",
    "url = f'https://api.nytimes.com/svc/archive/v1/{year}/{month}.json?api-key={key}'\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = requests.get(url)\n",
    "data.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = data.json()\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['copyright', 'response'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3791"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles['response']['docs']) # list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles['response']['docs'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Periods of backlash take shape after surges of Black progress. We have entered another such period.\n",
      "https://www.nytimes.com/2024/01/31/opinion/racist-backlash-history.html\n",
      "Periods of backlash take shape after surges of Black progress. We have entered another such period.\n",
      "Opinion\n"
     ]
    }
   ],
   "source": [
    "article0 = articles['response']['docs'][0]\n",
    "print(article0['abstract'])\n",
    "print(article0['web_url'])\n",
    "print(article0['snippet'])\n",
    "print(article0['section_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Top 5 Section Names for February 2024 Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_names = {}\n",
    "\n",
    "for doc in articles['response']['docs']:\n",
    "    section = doc['section_name']\n",
    "    if section in section_names:\n",
    "        section_names[section] += 1\n",
    "    else:\n",
    "        section_names[section] = 1\n",
    "\n",
    "len(section_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('U.S.', 734),\n",
       " ('World', 513),\n",
       " ('Arts', 326),\n",
       " ('Opinion', 272),\n",
       " ('Business Day', 244)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the section names by count\n",
    "sorted_sections = sorted(section_names.items(),key=lambda x:x[1],reverse=True)\n",
    "sorted_sections[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('U.S.', 734),\n",
       " ('World', 513),\n",
       " ('Arts', 326),\n",
       " ('Opinion', 272),\n",
       " ('Business Day', 244),\n",
       " ('New York', 200),\n",
       " ('Style', 174),\n",
       " ('Books', 139),\n",
       " ('Crosswords & Games', 125),\n",
       " ('Movies', 123)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALTERNATE METHOD FROM \"Week 6 Task Solutions.ipynb\"\n",
    "sections = [article['section_name'] for article in articles['response']['docs']]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "distDct = Counter(sections) # count the occurrences of each section name\n",
    "\n",
    "distDct.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles_by_year_month(year, month, key):\n",
    "    # create URL\n",
    "    url = f\"https://api.nytimes.com/svc/archive/v1/{year}/{month}.json?api-key={key}\"\n",
    "\n",
    "    # send the request to get the data\n",
    "    data = requests.get(url)\n",
    "    if data.status_code == 200:\n",
    "        print(\"Successfully got the data.\")\n",
    "\n",
    "    dataJson = data.json() # get response as JSON\n",
    "    documents = dataJson['response']['docs']\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a Python function that takes a date, for example, \"2024-02-12\", and returns the list of articles for that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def get_articles_by_date(date):\n",
    "    dt = datetime.datetime.strptime(date,'%Y-%m-%d')\n",
    "\n",
    "    # Get articles for given month and year\n",
    "    url = f'https://api.nytimes.com/svc/archive/v1/{dt.year}/{dt.month}.json?api-key={key}'\n",
    "    data = requests.get(url)\n",
    "    documents = data.json()['response']['docs']\n",
    "\n",
    "    articles = [doc for doc in documents if doc['pub_date'][:10] == date]\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    }
   ],
   "source": [
    "feb12_articles = get_articles_by_date('2024-02-12')\n",
    "print(len(feb12_articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write some code that explores whether the fields \"abstract\" and \"snippet\" are always the same or they differ. Which one has more information? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully got the data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3791"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = get_articles_by_year_month(2024, 2, key)\n",
    "len(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of articles with different abstracts and snippets (where snippet field was not empty): 5\n",
      "Only 0.13% of the abstracts in Feb 2024 were different from the snippets.\n"
     ]
    }
   ],
   "source": [
    "dif_abstract_snippet = []\n",
    "\n",
    "# find articles whose abstracts and snippets are not the same\n",
    "for article in articles:\n",
    "    abstract = article['abstract']\n",
    "    snippet = article['snippet']\n",
    "    if (abstract!= snippet) & (len(snippet) != 0):\n",
    "        dif_abstract_snippet.append(article)\n",
    "\n",
    "print(f\"Number of articles with different abstracts and snippets (where snippet field was not empty): {len(dif_abstract_snippet)}\")\n",
    "\n",
    "fraction = (len(dif_abstract_snippet)/len(articles))*100\n",
    "print(f\"Only {str(fraction)[:4]}% of the abstracts in Feb 2024 were different from the snippets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[288, 253, 342, 253, 249]\n",
      "[250, 250, 250, 250, 250]\n",
      "Average Abstract Length: 277.0\n",
      "Average Snippet Length: 250.0\n"
     ]
    }
   ],
   "source": [
    "abstract_lengths = [len(article['abstract']) for article in dif_abstract_snippet]\n",
    "snippet_lengths = [len(article['snippet']) for article in dif_abstract_snippet]\n",
    "\n",
    "print(abstract_lengths)\n",
    "print(snippet_lengths)\n",
    "\n",
    "avg_abstract = sum(abstract_lengths)/len(abstract_lengths)\n",
    "avg_snippet = sum(snippet_lengths)/len(snippet_lengths)\n",
    "\n",
    "print(f'Average Abstract Length: {avg_abstract}')\n",
    "print(f'Average Snippet Length: {avg_snippet}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a function that given one article (in its nested structure), creates a flat dictionary with keys that are relevant for analysis: either the abstract or snippet (see point 2); lead paragraph; headline; keywords concatenated via semicolon; pub_date; document_type; section_name; and type_of_material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['abstract', 'web_url', 'snippet', 'lead_paragraph', 'print_section', 'print_page', 'source', 'multimedia', 'headline', 'keywords', 'pub_date', 'document_type', 'news_desk', 'section_name', 'byline', 'type_of_material', '_id', 'word_count', 'uri'])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract --> <class 'str'>\n",
      "lead_paragraph --> <class 'str'>\n",
      "headline --> <class 'dict'>\n",
      "keywords --> <class 'list'>\n",
      "pub_date --> <class 'str'>\n",
      "document_type --> <class 'str'>\n",
      "section_name --> <class 'str'>\n",
      "type_of_material --> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "def get_relevant_keys(article):\n",
    "    '''Given a article (nested dictionary), returns a flat dictionary of keys\n",
    "    that are relevant for analysis.'''\n",
    "    keys = ['abstract','lead_paragraph','headline','keywords','pub_date','document_type','section_name','type_of_material']\n",
    "    \n",
    "    dct = {}\n",
    "    for key in keys:\n",
    "        dct[key] = article[key]\n",
    "        print(f'{key} --> {type(article[key])}')\n",
    "\n",
    "    # dct['headline_main'] = article['headline']['main']\n",
    "    # \n",
    "\n",
    "get_relevant_keys(articles[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'subject', 'value': 'Hate Crimes', 'rank': 1, 'major': 'N'},\n",
       " {'name': 'subject', 'value': 'Black People', 'rank': 2, 'major': 'N'},\n",
       " {'name': 'subject', 'value': 'Blacks', 'rank': 3, 'major': 'N'},\n",
       " {'name': 'subject', 'value': 'Discrimination', 'rank': 4, 'major': 'N'},\n",
       " {'name': 'subject',\n",
       "  'value': 'Civil Rights Movement (1954-68)',\n",
       "  'rank': 5,\n",
       "  'major': 'N'},\n",
       " {'name': 'subject', 'value': 'Reconstruction Era', 'rank': 6, 'major': 'N'},\n",
       " {'name': 'subject',\n",
       "  'value': 'Segregation and Desegregation',\n",
       "  'rank': 7,\n",
       "  'major': 'N'},\n",
       " {'name': 'persons',\n",
       "  'value': 'Nixon, Richard Milhous',\n",
       "  'rank': 8,\n",
       "  'major': 'N'}]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def concat_keywords(keywords_dct):\n",
    "    '''concatenates keywords from keywords_dct with semicolons'''\n",
    "    all_keywords = \"\"\n",
    "    for elt in keywords_dct:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Write another function that calls the function from point 3 on every article, to create a list of article dictionaries, and convert this list into a dataframe and then store it as a CSV file with the date-month in the title (this is important for point 5 below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Once you have done all of these in the notebook, create a Python script that can be called with a date (from a TikTok video). First, the script looks whether a CSV with cleaned articles is in our folder. If not, calls first the API function to get the articles and then the function that converts them into a CSV. Then, it loads the CSV into a datafram and it uses filtering to get the articles for the desired date. These articles will be used for the Semantic Similarity portion of the TikTok Project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
